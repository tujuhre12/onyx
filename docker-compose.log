cache-1  | 1:C 20 Jan 2025 22:49:10.998 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
cache-1  | 1:C 20 Jan 2025 22:49:10.998 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
cache-1  | 1:C 20 Jan 2025 22:49:10.998 * Redis version=7.4.2, bits=64, commit=00000000, modified=0, pid=1, just started
cache-1  | 1:C 20 Jan 2025 22:49:10.998 * Configuration loaded
cache-1  | 1:M 20 Jan 2025 22:49:10.999 * monotonic clock: POSIX clock_gettime
cache-1  | 1:M 20 Jan 2025 22:49:10.999 * Running mode=standalone, port=6379.
relational_db-1  | The files belonging to this database system will be owned by user "postgres".
relational_db-1  | This user must also own the server process.
relational_db-1  | 
relational_db-1  | The database cluster will be initialized with locale "en_US.utf8".
relational_db-1  | The default database encoding has accordingly been set to "UTF8".
relational_db-1  | The default text search configuration will be set to "english".
relational_db-1  | 
relational_db-1  | Data page checksums are disabled.
relational_db-1  | 
relational_db-1  | fixing permissions on existing directory /var/lib/postgresql/data ... ok
relational_db-1  | creating subdirectories ... ok
relational_db-1  | selecting dynamic shared memory implementation ... posix
relational_db-1  | selecting default max_connections ... 100
relational_db-1  | selecting default shared_buffers ... 128MB
relational_db-1  | selecting default time zone ... UTC
relational_db-1  | creating configuration files ... ok
relational_db-1  | running bootstrap script ... ok
relational_db-1  | sh: locale: not found
relational_db-1  | 2025-01-20 22:49:11.378 UTC [30] WARNING:  no usable system locales were found
relational_db-1  | performing post-bootstrap initialization ... ok
relational_db-1  | initdb: warning: enabling "trust" authentication for local connections
relational_db-1  | initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
relational_db-1  | syncing data to disk ... ok
relational_db-1  | 
relational_db-1  | 
relational_db-1  | Success. You can now start the database server using:
relational_db-1  | 
relational_db-1  |     pg_ctl -D /var/lib/postgresql/data -l logfile start
relational_db-1  | 
cache-1          | 1:M 20 Jan 2025 22:49:11.000 * Server initialized
relational_db-1  | waiting for server to start....2025-01-20 22:49:11.851 UTC [36] LOG:  starting PostgreSQL 15.2 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r4) 12.2.1 20220924, 64-bit
cache-1          | 1:M 20 Jan 2025 22:49:11.000 * Ready to accept connections tcp
relational_db-1  | 2025-01-20 22:49:11.855 UTC [36] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
relational_db-1  | 2025-01-20 22:49:11.866 UTC [39] LOG:  database system was shut down at 2025-01-20 22:49:11 UTC
relational_db-1  | 2025-01-20 22:49:11.876 UTC [36] LOG:  database system is ready to accept connections
relational_db-1  |  done
relational_db-1  | server started
relational_db-1  | 
relational_db-1  | /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
relational_db-1  | 
api_server-1     | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
api_server-1     | INFO  [alembic.runtime.migration] Will assume transactional DDL.
api_server-1     | The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
api_server-1     | 0it [00:00, ?it/s]0it [00:00, ?it/s]
api_server-1     | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade  -> 47433d30de82, Create IndexAttempt table
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade 47433d30de82 -> 6d387b3196c2, Basic Auth
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade 6d387b3196c2 -> 2666d766cb9b, Google OAuth2
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade 2666d766cb9b -> 27c6ecc08586, Permission Framework
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade 27c6ecc08586 -> 3c5e35aa9af0, Polling Document Count
index-1                  | runserver(configserver) running with pid: 19
index-1                  | Starting config proxy using tcp/541f2852aac7:19070 as config source(s)
index-1                  | Waiting for config proxy to start
index-1                  | runserver(configproxy) running with pid: 70
index-1                  | config proxy started after 0s (runserver pid 70)
index-1                  | runserver(config-sentinel) running with pid: 147
inference_model_server-1  | INFO:     Started server process [1]
index-1                   | [2025-01-20 22:49:11.025] INFO    configserver     just-start-configserver	JVM exec: [java -XX:ActiveProcessorCount=32 -XX:+PreserveFramePointer -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/vespa/var/crash -XX:ErrorFile=/opt/vespa/var/crash/hs_err_pid%p.log -XX:+ExitOnOutOfMemoryError -XX:MaxJavaStackTraceDepth=1000000 -XX:-OmitStackTraceInFastThrow --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=java.base/sun.security.ssl=ALL-UNNAMED -Djava.io.tmpdir=/opt/vespa/var/tmp -Djava.library.path=/opt/vespa/lib64:/opt/vespa-deps/lib64 -Djava.security.properties=/opt/vespa/conf/vespa/java.security.override -Djava.awt.headless=true -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.net.client.defaultConnectTimeout=5000 -Dsun.net.client.defaultReadTimeout=60000 -Djavax.net.ssl.keyStoreType=JKS -Djdk.tls.rejectClientInitiatedRenegotiation=true -Dfile.encoding=UTF-8 -Dorg.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger -Djdisc.bundle.path=/opt/vespa/lib/jars -Djdisc.logger.enabled=false -Djdisc.logger.level=WARNING -Dvespa.log.control.dir=/opt/vespa/var/db/vespa/logcontrol -Djdisc.export.packages= -Djdisc.config.file=/opt/vespa/var/jdisc_container/configserver.properties -Djdisc.cache.path=/opt/vespa/var/vespa/bundlecache/configserver -Djdisc.logger.tag=configserver -Dzookeeper_log_file_prefix=/opt/vespa/logs/vespa/zookeeper.configserver -Xms128m -Xmx2g -XX:+UseTransparentHugePages -cp /opt/vespa/lib/jars/jdisc_core-jar-with-dependencies.jar com.yahoo.jdisc.core.StandaloneMain standalone-container-jar-with-dependencies.jar]
inference_model_server-1  | INFO:     Waiting for application startup.
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:15 PM                        main.py   66: GPU is not available, using CPU
api_server-1             | INFO  [alembic.runtime.migration] Running upgrade 3c5e35aa9af0 -> 465f78d9b7f9, Larger Access Tokens for OAUTH
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:15 PM                        main.py   69: Moving contents of temp_huggingface to huggingface cache.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 465f78d9b7f9 -> d7111c1238cd, Remove Document IDs
index-1                   | [2025-01-20 22:49:11.060] INFO    configproxy      just-run-configproxy	JVM env:  LD_LIBRARY_PATH=/opt/vespa/lib64:/opt/vespa-deps/lib64 MALLOC_ARENA_MAX=1 VESPA_LOG_CONTROL_DIR=/opt/vespa/var/db/vespa/logcontrol VESPA_LOG_CONTROL_FILE=/opt/vespa/var/db/vespa/logcontrol/configproxy.logcontrol VESPA_LOG_TARGET=file:/opt/vespa/logs/vespa/vespa.log VESPA_SERVICE_NAME=configproxy
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:17 PM                        main.py   72: Moved contents of temp_huggingface to huggingface cache.
relational_db-1          | waiting for server to shut down....2025-01-20 22:49:11.944 UTC [36] LOG:  received fast shutdown request
relational_db-1           | 2025-01-20 22:49:11.948 UTC [36] LOG:  aborting any active transactions
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d7111c1238cd -> df0c7ad8a076, Added deletion_attempt table
relational_db-1           | 2025-01-20 22:49:11.949 UTC [36] LOG:  background worker "logical replication launcher" (PID 42) exited with exit code 1
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade df0c7ad8a076 -> b082fec533f0, Make 'last_attempt_status' nullable
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade b082fec533f0 -> e6a4bbc13fe4, Add index for retrieving latest index_attempt
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:17 PM                        main.py   75: Torch Threads: 16
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e6a4bbc13fe4 -> 5e84129c8be3, Add docs_indexed_column + time_started to index_attempt table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5e84129c8be3 -> 8aabb57f3b49, Restructure Document Indices
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:17 PM               custom_models.py  184: Warming up Intent Model: danswer/hybrid-intent-token-classifier
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 8aabb57f3b49 -> d929f0c1c6af, Feedback Feature
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d929f0c1c6af -> 5809c0787398, Add Chat Sessions
inference_model_server-1  | /usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5809c0787398 -> 8e26726b7683, Chat Context Addition
inference_model_server-1  |   warnings.warn(
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 8e26726b7683 -> d5645c915d0e, Remove deletion_attempt table
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:17 PM               custom_models.py   94: Loading model from local cache: danswer/hybrid-intent-token-classifier
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:17 PM               custom_models.py   99: Loaded model from local cache: /root/.cache/huggingface/hub/models--danswer--hybrid-intent-token-classifier/snapshots/54ed7e946f84a252c5d4e5d7a0bc839f466e9c64
indexing_model_server-1  | INFO:     Started server process [1]
inference_model_server-1  | INFO:     Application startup complete.
inference_model_server-1  | INFO:     Uvicorn running on http://0.0.0.0:9000 (Press CTRL+C to quit)
inference_model_server-1  | [92mINFO[0m:     01/20/2025 10:49:31 PM                    encoders.py  380: Embedding 1 texts with 88 total characters with local model: nomic-ai/nomic-embed-text-v1
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d5645c915d0e -> dba7f71618f5, Onyx Custom Tool Flow
relational_db-1           | 2025-01-20 22:49:11.949 UTC [37] LOG:  shutting down
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade dba7f71618f5 -> 767f1c2a00eb, Count Chat Tokens
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 767f1c2a00eb -> 800f48024ae9, Add ID to ConnectorCredentialPair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 800f48024ae9 -> 57b53544726e, Add document set tables
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 57b53544726e -> febe9eaa0644, Add document_set / persona relationship table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade febe9eaa0644 -> 7da543f5672f, Add SlackBotConfig table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7da543f5672f -> ae62505e3acc, Add SAML Accounts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ae62505e3acc -> e0a68a81d434, Add Chat Feedback
relational_db-1           | 2025-01-20 22:49:11.952 UTC [37] LOG:  checkpoint starting: shutdown immediate
nginx-1                   | Waiting for API server to boot up; this may take a minute or two...
index-1                   | [2025-01-20 22:49:11.060] INFO    configproxy      just-run-configproxy	JVM exec: [java -XX:+ExitOnOutOfMemoryError -XX:+PreserveFramePointer -XX:CompressedClassSpaceSize=32m -XX:MaxDirectMemorySize=32m -XX:ThreadStackSize=448 -XX:MaxJavaStackTraceDepth=1000 -XX:-OmitStackTraceInFastThrow -XX:ActiveProcessorCount=2 -Dproxyconfigsources=tcp/541f2852aac7:19070 -Djava.io.tmpdir=${VESPA_HOME}/var/tmp -Xms32m -Xmx128m -XX:+UseTransparentHugePages -cp /opt/vespa/lib/jars/config-proxy-jar-with-dependencies.jar com.yahoo.vespa.config.proxy.ProxyServer 19090]
index-1                   | [2025-01-20 22:49:11.192] INFO    configproxy      configproxy.com.yahoo.vespa.config.proxy.RpcConfigSourceClient	Could not connect to config source at tcp/541f2852aac7:19070
index-1                   | [2025-01-20 22:49:11.195] INFO    configproxy      configproxy.com.yahoo.vespa.config.proxy.RpcConfigSourceClient	Could not connect to any config source in set [tcp/541f2852aac7:19070], please make sure config server(s) are running.
index-1                   | [2025-01-20 22:49:11.225] INFO    configproxy      configproxy.com.yahoo.vespa.config.proxy.filedistribution.FileReferencesAndDownloadsMaintainer	Not running maintainer, since this is on a config server host
index-1                   | [2025-01-20 22:49:13.510] INFO    configserver     Container.com.yahoo.container.core.config.HandlersConfigurerDi	Installing bundles for application generation 0
index-1                   | [2025-01-20 22:49:13.577] INFO    configserver     Container.com.yahoo.container.core.config.ApplicationBundleLoader	Installed bundles: {[0]org.apache.felix.framework:7.0.5, [1]standalone-container:8.277.17, [2]configdefinitions:8.277.17, [3]config-provisioning:8.277.17, [4]config-bundle:8.277.17, [5]config-model-api:8.277.17, [6]config-model:8.277.17, [7]container-disc:8.277.17, [8]hosted-zone-api:8.277.17, [9]container-apache-http-client-bundle:8.277.17, [10]security-utils:8.277.17, [11]bcprov:1.76.0, [12]bcpkix:1.76.0, [13]bcutil:1.76.0, [14]com.fasterxml.jackson.core.jackson-annotations:2.16.0, [15]com.fasterxml.jackson.core.jackson-core:2.16.0, [16]com.fasterxml.jackson.core.jackson-databind:2.16.0, [17]com.fasterxml.jackson.datatype.jackson-datatype-jdk8:2.16.0, [18]com.fasterxml.jackson.datatype.jackson-datatype-jsr310:2.16.0, [19]javax.ws.rs-api:2.1.99.b01, [20]container-spifly:1.3.7, [21]javax.servlet-api:3.1.0, [22]container-search-and-docproc:8.277.17, [23]linguistics-components:8.277.17, [24]model-evaluation:8.277.17, [25]model-integration:8.277.17, [26]container-onnxruntime:8.277.17, [27]jdisc-security-filters:8.277.17, [28]vespa-athenz:8.277.17, [29]zkfacade:8.277.17, [30]zookeeper-server:8.277.17, [31]configserver:8.277.17, [32]config-model-fat:8.277.17, [33]flags:8.277.17, [34]http-client:8.277.17, [35]node-repository:8.277.17, [36]application-model:8.277.17, [37]orchestrator:8.277.17, [38]service-monitor:8.277.17, [39]configserver-flags:8.277.17}
index-1                   | [2025-01-20 22:49:17.011] INFO    configserver     Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-pool': min=64, max=3200, queue=0
index-1                   | [2025-01-20 22:49:17.110] INFO    configserver     Container.com.yahoo.container.jdisc.state.StateMonitor	Changing health status code from 'initializing' to 'up'
index-1                   | [2025-01-20 22:49:17.169] INFO    configserver     Container.com.yahoo.jdisc.http.server.jetty.JettyHttpServer	Threadpool size: min=48, max=48
index-1                   | [2025-01-20 22:49:17.352] INFO    configserver     Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-handler-common': min=64, max=64, queue=2560
index-1                   | [2025-01-20 22:49:17.433] INFO    configserver     Container.com.yahoo.container.jdisc.ConfiguredApplication	Switching to the latest deployed set of configurations and components. Application config generation: 0
index-1                   | [2025-01-20 22:49:20.560] INFO    configproxy      configproxy.com.yahoo.vespa.config.JRTConnection	Connecting to tcp/541f2852aac7:19070
index-1                   | [2025-01-20 22:49:20.590] INFO    configproxy      configproxy.com.yahoo.config.subscription.impl.JRTConfigRequester	Request failed: Failed request (No application exists) from Connection { Socket[addr=/172.18.0.2,port=60678,localport=19070] }\nConnection spec: tcp/541f2852aac7:19070
index-1                   | [2025-01-20 22:49:27.203] INFO    configproxy      configproxy.com.yahoo.vespa.config.proxy.DelayedResponseHandler	Timed out (timeout 15000) getting config name=cloud.config.sentinel,configId=hosts/541f2852aac7, will retry
index-1                   | [2025-01-20 22:49:31.093] INFO    configserver     Container.com.yahoo.vespa.config.server.ApplicationRepository	Session 2 prepared successfully. 
index-1                   | [2025-01-20 22:49:31.167] INFO    configserver     Container.com.yahoo.jrt.slobrok.api.Mirror	no location brokers available, retrying: [] (in 0.5 seconds)
index-1                   | [2025-01-20 22:49:31.201] INFO    configserver     Container.com.yahoo.vespa.config.server.session.SessionRepository	Session activated: 2
index-1                   | [2025-01-20 22:49:31.237] INFO    configserver     Container.com.yahoo.vespa.config.server.deploy.Deployment	Session 2 activated successfully using no host provisioner. Config generation 2. File references: [file 'a4a94fc36a6509d4']
index-1                   | [2025-01-20 22:49:31.317] INFO    config-sentinel  sentinel.config.frt.frtconfigagent	No response / error from config server. This is normal before an application package is deployed. (key: name=cloud.config.sentinel,configId=hosts/541f2852aac7) (errcode=103, validresponse:0), trying again in 6.000000 seconds
index-1                   | [2025-01-20 22:49:39.027] INFO    config-sentinel  sentinel.sentinel.connectivity	Connectivity check details: 541f2852aac7 -> OK: both ways connectivity verified
index-1                   | [2025-01-20 22:49:39.027] INFO    config-sentinel  sentinel.sentinel.connectivity	All connectivity checks OK, proceeding with service startup
index-1                   | [2025-01-20 22:49:39.108] INFO    metricsproxy-container vespa-start-container-daemon	JVM env:  LD_LIBRARY_PATH=/opt/vespa/lib64:/opt/vespa-deps/lib64 MALLOC_ARENA_MAX=1 VESPA_CONFIG_ID=admin/metrics/541f2852aac7 VESPA_LOG_CONTROL_DIR=/opt/vespa/var/db/vespa/logcontrol VESPA_LOG_CONTROL_FILE=/opt/vespa/var/db/vespa/logcontrol/metricsproxy-container.logcontrol VESPA_LOG_TARGET=file:/opt/vespa/logs/vespa/vespa.log VESPA_SERVICE_NAME=metricsproxy-container
index-1                   | [2025-01-20 22:49:39.108] INFO    metricsproxy-container vespa-start-container-daemon	JVM exec: [java -Dconfig.id=admin/metrics/541f2852aac7 -Djdisc.export.packages= -XX:+PreserveFramePointer -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/vespa/var/crash -XX:ErrorFile=/opt/vespa/var/crash/hs_err_pid%p.log -XX:+ExitOnOutOfMemoryError -XX:MaxJavaStackTraceDepth=1000000 --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=java.base/sun.security.ssl=ALL-UNNAMED -Djava.io.tmpdir=/opt/vespa/var/tmp -Djava.library.path=/opt/vespa/lib64:/opt/vespa-deps/lib64 -Djava.security.properties=/opt/vespa/conf/vespa/java.security.override -Djava.awt.headless=true -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.net.client.defaultConnectTimeout=5000 -Dsun.net.client.defaultReadTimeout=60000 -Djavax.net.ssl.keyStoreType=JKS -Djdk.tls.rejectClientInitiatedRenegotiation=true -Dfile.encoding=UTF-8 -Dorg.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger -XX:ActiveProcessorCount=1 -Xms32m -Xmx256m -XX:ThreadStackSize=512 -XX:MaxDirectMemorySize=48m -XX:+UseTransparentHugePages -XX:CompressedClassSpaceSize=32m -XX:+UseG1GC -XX:MaxTenuringThreshold=15 -Djdisc.bundle.path=/opt/vespa/lib/jars -Djdisc.logger.enabled=false -Djdisc.logger.level=WARNING -Dvespa.log.control.dir=/opt/vespa/var/db/vespa/logcontrol -Djdisc.config.file=/opt/vespa/var/jdisc_container/d3f931930b132860d7856987542526a1/jdisc.properties -Djdisc.cache.path=/opt/vespa/var/jdisc_container/d3f931930b132860d7856987542526a1/bundlecache -Djdisc.logger.tag=admin/metrics/541f2852aac7 -cp /opt/vespa/lib/jars/jdisc_core-jar-with-dependencies.jar com.yahoo.jdisc.core.StandaloneMain file:/opt/vespa/lib/jars/container-disc-jar-with-dependencies.jar]
index-1                   | [2025-01-20 22:49:39.134] INFO    container        vespa-start-container-daemon	JVM env:  JAVAVM_LD_PRELOAD=/opt/vespa/lib64/vespa/malloc/libvespamalloc.so LD_LIBRARY_PATH=/opt/vespa/lib64:/opt/vespa-deps/lib64 LD_PRELOAD=/opt/vespa/lib64/vespa/malloc/libvespamalloc.so MALLOC_ARENA_MAX=1 VESPA_CONFIG_ID=default/container.0 VESPA_LOG_CONTROL_DIR=/opt/vespa/var/db/vespa/logcontrol VESPA_LOG_CONTROL_FILE=/opt/vespa/var/db/vespa/logcontrol/container.logcontrol VESPA_LOG_TARGET=file:/opt/vespa/logs/vespa/vespa.log VESPA_SERVICE_NAME=container
index-1                   | [2025-01-20 22:49:39.134] INFO    container        vespa-start-container-daemon	JVM exec: [java -Dconfig.id=default/container.0 -Djdisc.export.packages= -XX:+PreserveFramePointer -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/vespa/var/crash -XX:ErrorFile=/opt/vespa/var/crash/hs_err_pid%p.log -XX:+ExitOnOutOfMemoryError -XX:MaxJavaStackTraceDepth=1000000 --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=java.base/sun.security.ssl=ALL-UNNAMED -Djava.io.tmpdir=/opt/vespa/var/tmp -Djava.library.path=/opt/vespa/lib64:/opt/vespa-deps/lib64 -Djava.security.properties=/opt/vespa/conf/vespa/java.security.override -Djava.awt.headless=true -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.net.client.defaultConnectTimeout=5000 -Dsun.net.client.defaultReadTimeout=60000 -Djavax.net.ssl.keyStoreType=JKS -Djdk.tls.rejectClientInitiatedRenegotiation=true -Dfile.encoding=UTF-8 -Dorg.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger -XX:ActiveProcessorCount=32 -Xms1536m -Xmx1536m -XX:ThreadStackSize=512 -XX:MaxDirectMemorySize=208m -XX:+UseTransparentHugePages -XX:+UseG1GC -XX:MaxTenuringThreshold=15 -Xlog:gc -Djdisc.bundle.path=/opt/vespa/lib/jars -Djdisc.logger.enabled=false -Djdisc.logger.level=WARNING -Dvespa.log.control.dir=/opt/vespa/var/db/vespa/logcontrol -Djdisc.config.file=/opt/vespa/var/jdisc_container/002feaba455a79270f003adbe0389fef/jdisc.properties -Djdisc.cache.path=/opt/vespa/var/jdisc_container/002feaba455a79270f003adbe0389fef/bundlecache -Djdisc.logger.tag=default/container.0 -Dzookeeper_log_file_prefix=/opt/vespa/logs/vespa/zookeeper.container -cp /opt/vespa/lib/jars/jdisc_core-jar-with-dependencies.jar com.yahoo.jdisc.core.StandaloneMain file:/opt/vespa/lib/jars/container-disc-jar-with-dependencies.jar]
index-1                   | [2025-01-20 22:49:39.153] INFO    container        stdout	[0.004s][info][gc] Using G1
index-1                   | [2025-01-20 22:49:39.178] INFO    container-clustercontroller vespa-start-container-daemon	JVM env:  LD_LIBRARY_PATH=/opt/vespa/lib64:/opt/vespa-deps/lib64 MALLOC_ARENA_MAX=1 VESPA_CONFIG_ID=admin/cluster-controllers/0 VESPA_LOG_CONTROL_DIR=/opt/vespa/var/db/vespa/logcontrol VESPA_LOG_CONTROL_FILE=/opt/vespa/var/db/vespa/logcontrol/container-clustercontroller.logcontrol VESPA_LOG_TARGET=file:/opt/vespa/logs/vespa/vespa.log VESPA_SERVICE_NAME=container-clustercontroller
index-1                   | [2025-01-20 22:49:39.178] INFO    container-clustercontroller vespa-start-container-daemon	JVM exec: [java -Dconfig.id=admin/cluster-controllers/0 -Djdisc.export.packages= -XX:+PreserveFramePointer -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/vespa/var/crash -XX:ErrorFile=/opt/vespa/var/crash/hs_err_pid%p.log -XX:+ExitOnOutOfMemoryError -XX:MaxJavaStackTraceDepth=1000000 --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=java.base/sun.security.ssl=ALL-UNNAMED -Djava.io.tmpdir=/opt/vespa/var/tmp -Djava.library.path=/opt/vespa/lib64:/opt/vespa-deps/lib64 -Djava.security.properties=/opt/vespa/conf/vespa/java.security.override -Djava.awt.headless=true -Dsun.rmi.dgc.client.gcInterval=3600000 -Dsun.net.client.defaultConnectTimeout=5000 -Dsun.net.client.defaultReadTimeout=60000 -Djavax.net.ssl.keyStoreType=JKS -Djdk.tls.rejectClientInitiatedRenegotiation=true -Dfile.encoding=UTF-8 -Dorg.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger -XX:ActiveProcessorCount=1 -Xms32m -Xmx128m -XX:ThreadStackSize=512 -XX:MaxDirectMemorySize=32m -XX:+UseTransparentHugePages -XX:CompressedClassSpaceSize=32m -Djdisc.bundle.path=/opt/vespa/lib/jars -Djdisc.logger.enabled=false -Djdisc.logger.level=WARNING -Dvespa.log.control.dir=/opt/vespa/var/db/vespa/logcontrol -Djdisc.config.file=/opt/vespa/var/jdisc_container/4044e8209f286312a68bbb54f8714922/jdisc.properties -Djdisc.cache.path=/opt/vespa/var/jdisc_container/4044e8209f286312a68bbb54f8714922/bundlecache -Djdisc.logger.tag=admin/cluster-controllers/0 -Dzookeeper_log_file_prefix=/opt/vespa/logs/vespa/zookeeper.container-clustercontroller -Dio.netty.allocator.pageSize=4096 -Dio.netty.allocator.maxOrder=5 -Dio.netty.allocator.numHeapArenas=1 -Dio.netty.allocator.numDirectArenas=1 -cp /opt/vespa/lib/jars/jdisc_core-jar-with-dependencies.jar com.yahoo.jdisc.core.StandaloneMain file:/opt/vespa/lib/jars/container-disc-jar-with-dependencies.jar]
index-1                   | [2025-01-20 22:49:39.276] INFO    searchnode       proton.proton.server.bootstrapconfigmanager	Filedistributorrpc config is changed
index-1                   | [2025-01-20 22:49:39.397] INFO    distributor      vds.slobrok.mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 0 service names)
index-1                   | [2025-01-20 22:49:39.448] INFO    distributor      vds.slobrok.mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 0 service names)
index-1                   | [2025-01-20 22:49:39.448] INFO    distributor      vds.slobrok.register	[RPC @ tcp/541f2852aac7:19111] registering storage/cluster.danswer_index/distributor/0/default with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:39.459] INFO    distributor      vds.slobrok.register	[RPC @ tcp/541f2852aac7:19112] registering storage/cluster.danswer_index/distributor/0 with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:39.498] INFO    distributor      vds.status	Starting status web server on port 19113.
index-1                   | [2025-01-20 22:49:39.500] INFO    searchnode       proton.proton.server.proton	Start initializing components: threads=2, configured=2
index-1                   | [2025-01-20 22:49:39.501] INFO    searchnode       proton.proton.server.proton	Add document database: doctypename(danswer_chunk_nomic_ai_nomic_embed_text_v1), configid(danswer_index/search/cluster.danswer_index/danswer_chunk_nomic_ai_nomic_embed_text_v1)
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:31 PM                    encoders.py  282: Loading nomic-ai/nomic-embed-text-v1
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e0a68a81d434 -> 3b25685ff73c, Move is_public to cc_pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 3b25685ff73c -> 904451035c9b, Store Tool Details
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 904451035c9b -> a570b80a5f20, UserGroup tables
indexing_model_server-1   | INFO:     Waiting for application startup.
index-1                   | [2025-01-20 22:49:39.622] INFO    configserver     Container.com.yahoo.jrt.slobrok.api.Mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 2 service names)
inference_model_server-1  | /usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
relational_db-1           | 2025-01-20 22:49:11.970 UTC [37] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.005 s, sync=0.003 s, total=0.021 s; sync files=2, longest=0.002 s, average=0.002 s; distance=0 kB, estimate=0 kB
relational_db-1           | 2025-01-20 22:49:11.973 UTC [36] LOG:  database system is shut down
relational_db-1           |  done
relational_db-1           | server stopped
relational_db-1           | 
relational_db-1           | PostgreSQL init process complete; ready for start up.
relational_db-1           | 
relational_db-1           | 2025-01-20 22:49:12.070 UTC [1] LOG:  starting PostgreSQL 15.2 on x86_64-pc-linux-musl, compiled by gcc (Alpine 12.2.1_git20220924-r4) 12.2.1 20220924, 64-bit
relational_db-1           | 2025-01-20 22:49:12.070 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
relational_db-1           | 2025-01-20 22:49:12.070 UTC [1] LOG:  listening on IPv6 address "::", port 5432
relational_db-1           | 2025-01-20 22:49:12.077 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
relational_db-1           | 2025-01-20 22:49:12.085 UTC [50] LOG:  database system was shut down at 2025-01-20 22:49:11 UTC
relational_db-1           | 2025-01-20 22:49:12.091 UTC [1] LOG:  database system is ready to accept connections
relational_db-1           | 2025-01-20 22:49:16.552 UTC [56] ERROR:  column key_value_store.encrypted_value does not exist at character 100
relational_db-1           | 2025-01-20 22:49:16.552 UTC [56] STATEMENT:  SELECT key_value_store.key AS key_value_store_key, key_value_store.value AS key_value_store_value, key_value_store.encrypted_value AS key_value_store_encrypted_value 
relational_db-1           | 	FROM key_value_store 
relational_db-1           | 	WHERE key_value_store.key = 'token_budget_settings' 
relational_db-1           | 	 LIMIT 1
relational_db-1           | 2025-01-20 22:49:16.861 UTC [57] ERROR:  relation "slack_bot" does not exist at character 104
relational_db-1           | 2025-01-20 22:49:16.861 UTC [57] STATEMENT:  SELECT slack_bot.id, slack_bot.name, slack_bot.enabled, slack_bot.bot_token, slack_bot.app_token 
relational_db-1           | 	FROM slack_bot
relational_db-1           | 2025-01-20 22:49:18.931 UTC [59] ERROR:  column index_attempt.search_settings_id does not exist at character 288
indexing_model_server-1   | [94mNOTICE[0m:   01/20/2025 10:49:15 PM                        main.py   66: GPU is not available, using CPU
inference_model_server-1  |   warnings.warn(
inference_model_server-1  | <All keys matched successfully>
inference_model_server-1  | [92mINFO[0m:     01/20/2025 10:49:33 PM                    encoders.py  402: Successfully embedded 1 texts with 88 total characters with local model nomic-ai/nomic-embed-text-v1 in 1.96
inference_model_server-1  | [94mNOTICE[0m:   01/20/2025 10:49:33 PM                       utils.py   38: embed_text took 1.9656906127929688 seconds
inference_model_server-1  | [92mINFO[0m:     01/20/2025 10:49:33 PM                    h11_impl.py  499: 172.18.0.7:33674 - "POST /encoder/bi-encoder-embed HTTP/1.1" 200
inference_model_server-1  | [92mINFO[0m:     01/20/2025 10:49:33 PM                    h11_impl.py  499: 172.18.0.7:55486 - "GET /api/gpu-status HTTP/1.1" 200
index-1                   | [2025-01-20 22:49:39.733] INFO    searchnode       proton.slobrok.register	[RPC @ tcp/541f2852aac7:19105] registering danswer_index/search/cluster.danswer_index/0/realtimecontroller with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:39.737] INFO    searchnode       proton.proton.server.proton	Done initializing components
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade a570b80a5f20 -> 7ccea01261f6, Store Chat Retrieval Docs
index-1                   | [2025-01-20 22:49:39.768] INFO    searchnode       proton.proton.server.documentdb	DocumentDB(danswer_chunk_nomic_ai_nomic_embed_text_v1): Applied config, state=APPLY_LIVE_CONFIG, config_state=OK, saved=no, serialNum=2, 0.003s of 0.012s in write thread
index-1                   | [2025-01-20 22:49:40.104] INFO    logd             logdemon	state server listening on port 19089
index-1                   | [2025-01-20 22:49:40.119] INFO    searchnode       proton.persistence.filestor.manager	Completed listing of 0 buckets in 0.024 milliseconds
nginx-1                   | If this takes more than ~5 minutes, check the logs of the API server container for errors with the following command:
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7ccea01261f6 -> 78dbe7e38469, Task Tracking
nginx-1                   | 
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 78dbe7e38469 -> 7f99be1cb9f5, Add index for getting documents just by connector id / credential id
index-1                   | [2025-01-20 22:49:40.119] INFO    searchnode       proton.node.server	Storage node ready. Done initializing. Giving out of sequence metric event. Config id is danswer_index/storage/0
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7f99be1cb9f5 -> 30c1d5744104, Persona Datetime Aware
index-1                   | [2025-01-20 22:49:40.223] INFO    container        stdout	[1.074s][info][gc] GC(0) Pause Young (Normal) (G1 Evacuation Pause) 80M->12M(1536M) 10.571ms
nginx-1                   | docker logs onyx-stack_api_server-1
index-1                   | [2025-01-20 22:49:40.230] INFO    searchnode       proton.slobrok.mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 3 service names)
nginx-1                   | 
nginx-1                   | API server responded with 000, retrying in 5 seconds...
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 30c1d5744104 -> ffc707a226b4, Basic Document Metadata
nginx-1                   | API server responded with 000, retrying in 5 seconds...
relational_db-1           | 2025-01-20 22:49:18.931 UTC [59] STATEMENT:  SELECT index_attempt.id, index_attempt.connector_credential_pair_id, index_attempt.from_beginning, index_attempt.status, index_attempt.new_docs_indexed, index_attempt.total_docs_indexed, index_attempt.docs_removed_from_index, index_attempt.error_msg, index_attempt.full_exception_trace, index_attempt.search_settings_id, index_attempt.time_created, index_attempt.time_started, index_attempt.time_updated 
index-1                   | [2025-01-20 22:49:40.281] INFO    searchnode       proton.slobrok.register	[RPC @ tcp/541f2852aac7:19102] registering storage/cluster.danswer_index/storage/0/default with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:40.282] INFO    searchnode       proton.slobrok.mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 4 service names)
nginx-1                   | API server responded with 000, retrying in 5 seconds...
indexing_model_server-1   | [94mNOTICE[0m:   01/20/2025 10:49:15 PM                        main.py   69: Moving contents of temp_huggingface to huggingface cache.
indexing_model_server-1   | [94mNOTICE[0m:   01/20/2025 10:49:17 PM                        main.py   72: Moved contents of temp_huggingface to huggingface cache.
indexing_model_server-1   | [94mNOTICE[0m:   01/20/2025 10:49:17 PM                        main.py   75: Torch Threads: 16
indexing_model_server-1   | [94mNOTICE[0m:   01/20/2025 10:49:17 PM                        main.py   80: This model server should only run document indexing.
indexing_model_server-1   | INFO:     Application startup complete.
web_server-1              |    â–² Next.js 15.0.2
index-1                   | [2025-01-20 22:49:40.283] INFO    searchnode       proton.slobrok.register	[RPC @ tcp/541f2852aac7:19103] registering storage/cluster.danswer_index/storage/0 with location broker tcp/541f2852aac7:19099 completed successfully
relational_db-1           | 	FROM index_attempt 
index-1                   | [2025-01-20 22:49:40.312] INFO    searchnode       proton.status	Starting status web server on port 19104.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ffc707a226b4 -> 9d97fecfab7f, Added retrieved docs to query event
index-1                   | [2025-01-20 22:49:40.946] INFO    metricsproxy-container Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-pool': min=1, max=1, queue=50
index-1                   | [2025-01-20 22:49:41.013] INFO    container        stdout	[1.865s][info][gc] GC(1) Pause Young (Normal) (G1 Evacuation Pause) 80M->16M(1536M) 6.659ms
index-1                   | [2025-01-20 22:49:41.146] INFO    metricsproxy-container Container.com.yahoo.jdisc.http.server.jetty.JettyHttpServer	Threadpool size: min=4, max=4
index-1                   | [2025-01-20 22:49:41.431] INFO    metricsproxy-container Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-handler-common': min=8, max=8, queue=650
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 9d97fecfab7f -> 46625e4745d4, Remove Native Enum
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 46625e4745d4 -> d61e513bef0a, Add Total Docs for Index Attempt
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d61e513bef0a -> 77d07dffae64, forcibly remove more enum types from postgres
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 77d07dffae64 -> 15326fcec57e, Introduce Onyx APIs
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 15326fcec57e -> 80696cf850ae, Add chat session to query_event
indexing_model_server-1   | INFO:     Uvicorn running on http://0.0.0.0:9000 (Press CTRL+C to quit)
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 80696cf850ae -> e86866a9c78a, Add persona to chat_session
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e86866a9c78a -> 7da0ae5ad583, Add description to persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7da0ae5ad583 -> 50b683a8295c, Add additional retrieval controls to Persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 50b683a8295c -> baf71f781b9e, Add llm_model_version_override to Persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade baf71f781b9e -> b156fa702355, Chat Reworked
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade b156fa702355 -> 76b60d407dfb, CC-Pair Name not Unique
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 76b60d407dfb -> 891cd83c87a8, Add is_visible to Persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 891cd83c87a8 -> 904e5138fffb, Tags
nginx-1                   | API server responded with 000, retrying in 5 seconds...
nginx-1                   | API server responded with 000, retrying in 5 seconds...
nginx-1                   | API server responded with 000, retrying in 5 seconds...
nginx-1                   | API server responded with 000, retrying in 5 seconds...
nginx-1                   | API server responded with 000, retrying in 5 seconds...
nginx-1                   | API server responded with 200, starting nginx...
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: using the "epoll" event method
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: nginx/1.23.4
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: built by gcc 12.2.1 20220924 (Alpine 12.2.1_git20220924-r4) 
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: OS: Linux 6.8.0-1021-aws
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: getrlimit(RLIMIT_NOFILE): 1048576:1048576
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker processes
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 38
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 39
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 40
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 41
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 42
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 43
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 44
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 45
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 46
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 47
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 48
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 49
index-1                   | [2025-01-20 22:49:41.449] INFO    metricsproxy-container Container.com.yahoo.container.jdisc.state.StateMonitor	Changing health status code from 'initializing' to 'up'
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 904e5138fffb -> 79acd316403a, Add api_key table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 79acd316403a -> 7f726bad5367, Slack Followup
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7f726bad5367 -> dbaa756c2ccf, Embedding Models
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade dbaa756c2ccf -> ec3ec2eabf7b, Index From Beginning
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ec3ec2eabf7b -> 8987770549c0, Add full exception stack trace
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 50
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 8987770549c0 -> 5f4b8568a221, add removed documents to index_attempt
web_server-1              |    - Local:        http://72414a93a15f:3000
web_server-1              |    - Network:      http://172.18.0.9:3000
web_server-1              | 
web_server-1              |  âœ“ Starting...
web_server-1              |  âœ“ Ready in 62ms
index-1                   | [2025-01-20 22:49:41.481] INFO    container-clustercontroller Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-pool': min=1, max=1, queue=50
index-1                   | [2025-01-20 22:49:41.515] INFO    metricsproxy-container Container.com.yahoo.container.jdisc.ConfiguredApplication	Switching to the latest deployed set of configurations and components. Application config generation: 2
index-1                   | [2025-01-20 22:49:41.518] INFO    metricsproxy-container Container.com.yahoo.container.jdisc.ConfiguredApplication	Registered name 'vespa/service/admin/metrics/541f2852aac7' at tcp/541f2852aac7:19094 with: [tcp/541f2852aac7:19099]
index-1                   | [2025-01-20 22:49:41.522] INFO    metricsproxy-container Container.com.yahoo.jrt.slobrok.api.Register	[RPC @ tcp/541f2852aac7:19094] registering vespa/service/admin/metrics/541f2852aac7 with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:41.831] INFO    container-clustercontroller Container.com.yahoo.jdisc.http.server.jetty.JettyHttpServer	Threadpool size: min=4, max=4
index-1                   | [2025-01-20 22:49:41.981] INFO    container-clustercontroller Container.com.yahoo.container.jdisc.state.StateMonitor	Changing health status code from 'initializing' to 'up'
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 51
index-1                   | [2025-01-20 22:49:42.062] INFO    container        stdout	[2.914s][info][gc] GC(2) Pause Young (Concurrent Start) (Metadata GC Threshold) 31M->18M(1536M) 4.491ms
index-1                   | [2025-01-20 22:49:42.062] INFO    container        stdout	[2.914s][info][gc] GC(3) Concurrent Mark Cycle
index-1                   | [2025-01-20 22:49:42.084] INFO    container        stdout	[2.924s][info][gc] GC(3) Pause Remark 20M->20M(1536M) 4.311ms
relational_db-1           | 	WHERE index_attempt.status = 'NOT_STARTED' ORDER BY index_attempt.time_created
background-1              | 2025-01-20 22:49:11,432 INFO Set uid to user 0 succeeded
relational_db-1           | 2025-01-20 22:49:20.580 UTC [54] WARNING:  there is no transaction in progress
index-1                   | [2025-01-20 22:49:42.084] INFO    container        stdout	[2.926s][info][gc] GC(3) Pause Cleanup 21M->21M(1536M) 0.218ms
index-1                   | [2025-01-20 22:49:42.084] INFO    container        stdout	[2.933s][info][gc] GC(3) Concurrent Mark Cycle 19.323ms
index-1                   | [2025-01-20 22:49:42.133] INFO    container-clustercontroller Container.ai.vespa.reindexing.ReindexingCurator	Creating initial reindexing status at 'reindexing/v1/danswer_index/status'
index-1                   | [2025-01-20 22:49:42.183] INFO    container-clustercontroller Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-handler-common': min=8, max=8, queue=650
index-1                   | [2025-01-20 22:49:42.250] INFO    container-clustercontroller Container.com.yahoo.jrt.slobrok.api.Mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 6 service names)
index-1                   | [2025-01-20 22:49:42.284] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.MasterElectionHandler	Cluster 'danswer_index': Clearing master data as we lost connection on node 0
index-1                   | [2025-01-20 22:49:42.285] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.FleetController	Cluster 'danswer_index': Starting tick loop
index-1                   | [2025-01-20 22:49:42.285] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.DatabaseHandler	Cluster 'danswer_index': Setting up new ZooKeeper session at 541f2852aac7:2181
index-1                   | [2025-01-20 22:49:42.307] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Connection to zookeeper server established. Refetching master data
index-1                   | [2025-01-20 22:49:42.338] INFO    container-clustercontroller Container.com.yahoo.container.jdisc.ConfiguredApplication	Switching to the latest deployed set of configurations and components. Application config generation: 2
index-1                   | [2025-01-20 22:49:42.341] INFO    container-clustercontroller Container.com.yahoo.container.jdisc.ConfiguredApplication	Registered name 'vespa/service/admin/cluster-controllers/0' at tcp/541f2852aac7:19115 with: [tcp/541f2852aac7:19099]
index-1                   | [2025-01-20 22:49:42.344] INFO    container-clustercontroller Container.com.yahoo.jrt.slobrok.api.Register	[RPC @ tcp/541f2852aac7:19115] registering vespa/service/admin/cluster-controllers/0 with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:42.393] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Creating ephemeral master vote node with vote to self.
background-1              | 2025-01-20 22:49:11,433 INFO supervisord started with pid 7
index-1                   | [2025-01-20 22:49:42.410] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.DatabaseHandler	Cluster 'danswer_index': Done setting up new ZooKeeper session at 541f2852aac7:2181
background-1              | 2025-01-20 22:49:12,436 INFO spawned: 'celery_beat' with pid 8
index-1                   | [2025-01-20 22:49:42.414] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.MasterDataGatherer	Fleetcontroller 0: Got node list response from /vespa/fleetcontroller/danswer_index/indexes version 0 with 1 nodes
background-1              | 2025-01-20 22:49:12,437 INFO spawned: 'celery_worker_heavy' with pid 9
index-1                   | [2025-01-20 22:49:42.425] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Stored new vote in ephemeral node. 0 -> 0
background-1              | 2025-01-20 22:49:12,439 INFO spawned: 'celery_worker_indexing' with pid 10
index-1                   | [2025-01-20 22:49:42.427] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.MasterDataGatherer	Fleetcontroller 0: Got vote data from path /vespa/fleetcontroller/danswer_index/indexes/0 with code 0 and data 0
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 52
background-1              | 2025-01-20 22:49:12,440 INFO spawned: 'celery_worker_light' with pid 11
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 53
background-1              | 2025-01-20 22:49:12,441 INFO spawned: 'celery_worker_monitoring' with pid 12
background-1              | 2025-01-20 22:49:12,443 INFO spawned: 'celery_worker_primary' with pid 13
background-1              | 2025-01-20 22:49:12,444 INFO spawned: 'log-redirect-handler' with pid 14
background-1              | 2025-01-20 22:49:12,445 INFO spawned: 'slack_bot' with pid 15
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:12 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:12 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:12 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:12 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | 2025-01-20 22:49:13,447 INFO success: log-redirect-handler entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:16 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   28: Initializing DynamicTenantScheduler
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   38: Setting up initial schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   40: Initial schedule setup complete
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  127: _try_updating_schedule starting
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  130: Found 1 IDs
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  145: Found 0 existing items in schedule
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5f4b8568a221 -> 0a2b51deb0b8, Add starter prompts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 0a2b51deb0b8 -> fcd135795f21, Add slack bot display type
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade fcd135795f21 -> e50154680a5c, No Source Enum
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e50154680a5c -> 173cae5bba26, Port Config Store
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 173cae5bba26 -> 91fd3b470d1a, Remove DocumentSource from Tag
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 91fd3b470d1a -> e91df4e935ef, Private Personas DocumentSets
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e91df4e935ef -> 4738e4b3bae1, PG File Store
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4738e4b3bae1 -> 776b3bbe9092, Remove Remaining Enums
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  149: Processing new tenant: None
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   65: Fetching tasks to schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  159: Schedule update required
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  186: _try_updating_schedule: Schedule updated successfully
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   35: Set reload interval to 0:02:00
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   28: Initializing DynamicTenantScheduler
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:28  : onyx.background.celery.apps.beat Initializing DynamicTenantScheduler
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   38: Setting up initial schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:38  : onyx.background.celery.apps.beat Setting up initial schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   40: Initial schedule setup complete
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:40  : onyx.background.celery.apps.beat Initial schedule setup complete
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   38: Setting up initial schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:38  : onyx.background.celery.apps.beat Setting up initial schedule
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:16 PM         beat.py:524 : celery.beat Removing corrupted schedule file 'celerybeat-schedule': error(11, 'Resource temporarily unavailable')
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/celery/beat.py", line 531, in setup_schedule
background-1              |     self._store = self._open_schedule()
background-1              |                   ^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/celery/beat.py", line 521, in _open_schedule
background-1              |     return self.persistence.open(self.schedule_filename, writeback=True)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/shelve.py", line 243, in open
background-1              |     return DbfilenameShelf(filename, flag, protocol, writeback)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/shelve.py", line 227, in __init__
background-1              |     Shelf.__init__(self, dbm.open(filename, flag), protocol, writeback)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/dbm/__init__.py", line 95, in open
background-1              |     return mod.open(file, flag, mode)
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 54
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 55
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 56
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 776b3bbe9092 -> 38eda64af7fe, Add chat session sharing
index-1                   | [2025-01-20 22:49:42.429] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.MasterDataGatherer	Fleetcontroller 0: Got vote from fleetcontroller 0. Altering vote from null to 0.
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 57
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 58
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 59
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 60
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 61
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 38eda64af7fe -> ecab2b3f1a3b, Add overrides to the chat session
index-1                   | [2025-01-20 22:49:42.440] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type MASTER_ELECTION @1737413382440: This node just became node state gatherer as we are fleetcontroller master candidate.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ecab2b3f1a3b -> 475fcefe8826, Add name to api_key
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 475fcefe8826 -> 72bdc9929a46, Permission Auto Sync Framework
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 72bdc9929a46 -> fad14119fb92, Delete Tags with wrong Enum
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade fad14119fb92 -> 703313b75876, Add TokenRateLimit Tables
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 703313b75876 -> 401c1ac29467, Add tables for UI-based LLM configuration
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 401c1ac29467 -> ef7da92f7213, Add files to ChatMessage
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ef7da92f7213 -> 7547d982db8f, Chat Folders
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7547d982db8f -> 570282d33c49, Track Onyxbot Explicitly
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 570282d33c49 -> 0a98909f2757, Enable Encrypted Fields
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 0a98909f2757 -> 643a84a42a33, Add user-configured names to LLMProvider
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 643a84a42a33 -> f1c6478c3fd8, Add pre-defined feedback
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade f1c6478c3fd8 -> 3879338f8ba1, Add tool table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 3879338f8ba1 -> 70f00c45c0f2, More Descriptive Filestore
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 70f00c45c0f2 -> ec85f2b3c544, Remove Last Attempt Status from CC Pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ec85f2b3c544 -> a3bfd0d64902, Add chosen_assistants to User table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade a3bfd0d64902 -> b85f02ec1308, fix-file-type-migration
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade b85f02ec1308 -> 48d14957fe80, Add support for custom tools
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 48d14957fe80 -> e209dc5a8156, added-prune-frequency
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e209dc5a8156 -> 0568ccf46a6b, Add thread specific model selection
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 0568ccf46a6b -> bc9771dccadf, create usage reports table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade bc9771dccadf -> 23957775e5f5, remove-feedback-foreignkey-constraint
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 23957775e5f5 -> 3a7802814195, add alternate assistant to chat message
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 3a7802814195 -> c18cdf4b497e, Add standard_answer tables
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c18cdf4b497e -> 4505fd7302e1, added is_internet to DBDoc
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4505fd7302e1 -> 7aea705850d5, added slack_auto_filter
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7aea705850d5 -> d716b0791ddd, combined slack id fields
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d716b0791ddd -> 44f856ae2a4a, add cloud embedding model and update embedding_model
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 44f856ae2a4a -> b896bbd0d5a7, backfill is_internet data to False
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade b896bbd0d5a7 -> 05c07bf07c00, add search doc relevance details
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 05c07bf07c00 -> 795b20b85b4b, add_llm_group_permissions_control
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 795b20b85b4b -> 91ffac7e65b3, add expiry time
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 91ffac7e65b3 -> 325975216eb3, Add icon_color and icon_shape to Persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 325975216eb3 -> 473a1a7ca408, Add display_model_names to llm_provider
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 473a1a7ca408 -> 4ea2c93919c1, Add type to credentials
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4ea2c93919c1 -> 8a87bd6ec550, associate index attempts with ccpair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 8a87bd6ec550 -> 08a1eda20fe1, add_indexing_start_to_connector
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 08a1eda20fe1 -> e1392f05e840, Added input prompts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e1392f05e840 -> 1d6ad76d1f37, Rename index_origin to index_recursively
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 1d6ad76d1f37 -> 5fc1f54cc252, hybrid-enum
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5fc1f54cc252 -> 213fd978c6d8, notifications
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 213fd978c6d8 -> 7477a5f5d728, Added model defaults for users
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 7477a5f5d728 -> 4a951134c801, Moved status to connector credential pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4a951134c801 -> c5b692fa265c, Add index_attempt_errors table
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 62
index-1                   | [2025-01-20 22:49:42.442] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Read cluster state version 0 from ZooKeeper (znode version 0)
index-1                   | [2025-01-20 22:49:42.443] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.MasterElectionHandler	Cluster 'danswer_index': Got new fleet data with 1 entries: {0=0}
index-1                   | [2025-01-20 22:49:42.443] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.MasterElectionHandler	Cluster 'danswer_index': Handling new master election, as we have received 1 entries
index-1                   | [2025-01-20 22:49:42.443] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.MasterElectionHandler	Cluster 'danswer_index': Got master election state data(0 -> 0).
index-1                   | [2025-01-20 22:49:42.443] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.MasterElectionHandler	Cluster 'danswer_index': 0 is newly elected master
index-1                   | [2025-01-20 22:49:42.444] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Read cluster state version 0 from ZooKeeper (znode version 0)
index-1                   | [2025-01-20 22:49:42.449] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.FleetController	Cluster 'danswer_index': Loaded previous cluster state bundle from ZooKeeper: ClusterStateBundle('')
index-1                   | [2025-01-20 22:49:42.449] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type MASTER_ELECTION @1737413382449: This node just became fleetcontroller master. Bumped version to 1 to be in line.
index-1                   | [2025-01-20 22:49:42.450] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: storage.0: Altered min distribution bit count from 16 to 58
index-1                   | [2025-01-20 22:49:42.454] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: distributor.0: Altered min distribution bit count from 16 to 58
index-1                   | [2025-01-20 22:49:42.457] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: storage.0: Altered node state in cluster state from 'D' to 'U, t 1737413380, b 58'
index-1                   | [2025-01-20 22:49:42.457] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: distributor.0: Altered node state in cluster state from 'D' to 'U, t 1737413379, b 58'
index-1                   | [2025-01-20 22:49:42.459] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type SYSTEMSTATE @1737413382454: New cluster state version 2. Change from last: version: 0 => 2, bits: 16 => 8, storage: 0: [Down => Up, minUsedBits: 16 => 58, startTimestamp: 0 => 1737413380], distributor: 0: [Down => Up, minUsedBits: 16 => 58, startTimestamp: 0 => 1737413379]
index-1                   | [2025-01-20 22:49:42.459] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type SYSTEMSTATE @1737413382454: Altering distribution bits in system from 16 to 8
index-1                   | [2025-01-20 22:49:42.460] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Storing new cluster state version in ZooKeeper: 2
index-1                   | [2025-01-20 22:49:42.486] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.FleetController	Cluster 'danswer_index': Master moratorium complete: all nodes have reported in
index-1                   | [2025-01-20 22:49:42.486] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.SystemStateBroadcaster	Cluster 'danswer_index': Publishing cluster state version 2
index-1                   | [2025-01-20 22:49:42.490] INFO    searchnode       proton.state.manager	Transitioning from baseline state 'Down' to 'Up'  (cluster state version 2)
index-1                   | [2025-01-20 22:49:42.491] INFO    distributor      vds.node.server	Distributor node ready. Done initializing. Giving out of sequence metric event. Config id is danswer_index/distributor/0
index-1                   | [2025-01-20 22:49:42.491] INFO    distributor      vds.state.manager	Transitioning from baseline state 'Down' to 'Up'  (cluster state version 2)
index-1                   | [2025-01-20 22:49:42.493] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type SYSTEMSTATE @1737413382493: Reset 2 start timestamps as all available distributors have seen newest cluster state.
index-1                   | [2025-01-20 22:49:42.507] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: storage.0: Altered node state in cluster state from 'U, t 1737413380, b 58' to 'U, b 58'
index-1                   | [2025-01-20 22:49:42.507] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: distributor.0: Altered node state in cluster state from 'U, t 1737413379, b 58' to 'U, b 58'
index-1                   | [2025-01-20 22:49:42.507] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Cluster event type SYSTEMSTATE @1737413382506: New cluster state version 3. Change from last: version: 2 => 3, storage: 0: startTimestamp: 1737413380 => 0, distributor: 0: startTimestamp: 1737413379 => 0
index-1                   | [2025-01-20 22:49:42.507] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.database.ZooKeeperDatabase	Cluster 'danswer_index': Storing new cluster state version in ZooKeeper: 3
index-1                   | [2025-01-20 22:49:42.608] INFO    container        stdout	[3.459s][info][gc] GC(4) Pause Young (Normal) (G1 Evacuation Pause) 184M->64M(1536M) 8.434ms
index-1                   | [2025-01-20 22:49:42.728] INFO    container        Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'search-handler': min=64, max=64, queue=2560
index-1                   | [2025-01-20 22:49:42.755] INFO    container        Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-pool': min=64, max=3200, queue=0
index-1                   | [2025-01-20 22:49:42.839] INFO    container        Container.com.yahoo.search.cluster.ClusterMonitor	Starting cluster monitor thread search.clustermonitor.dispatcher.danswer_index
index-1                   | [2025-01-20 22:49:43.468] INFO    container        stdout	[4.320s][info][gc] GC(5) Pause Young (Normal) (G1 Evacuation Pause) 405M->78M(1536M) 12.085ms
index-1                   | [2025-01-20 22:49:44.143] INFO    container        stdout	[4.994s][info][gc] GC(6) Pause Young (Normal) (G1 Evacuation Pause) 415M->80M(1536M) 5.559ms
index-1                   | [2025-01-20 22:49:44.875] INFO    container        stdout	[5.726s][info][gc] GC(7) Pause Young (Normal) (G1 Evacuation Pause) 449M->78M(1536M) 6.989ms
index-1                   | [2025-01-20 22:49:45.198] INFO    searchnode       proton.metrics.manager	Metrics registration changes detected. Handling changes.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c5b692fa265c -> da4c21c69164, chosen_assistants changed to jsonb
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade da4c21c69164 -> d9ec13955951, Remove _alt suffix from model_name
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade d9ec13955951 -> 4b08d97e175a, change default prune_freq
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4b08d97e175a -> 2d2304e27d8c, Add Above Below to Persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 2d2304e27d8c -> ee3f4b47fad5, Added alternate model to chat message
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ee3f4b47fad5 -> 351faebd379d, Add curator fields
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 351faebd379d -> f17bf3b0d9f1, embedding provider by provider type
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade f17bf3b0d9f1 -> 1f60f60c3401, embedding model -> search settings
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 1f60f60c3401 -> a3795dce87be, migration confluence to be explicit
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade a3795dce87be -> bceb1e139447, Add base_url to CloudEmbeddingProvider
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade bceb1e139447 -> ba98eba0f66a, add support for litellm proxy in reranking
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ba98eba0f66a -> f7e58d357687, add has_web_login column to user
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade f7e58d357687 -> 52a219fb5233, Add last synced and last modified to document table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 52a219fb5233 -> 0ebb1d516877, add ccpair deletion failure message
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 0ebb1d516877 -> efb35676026c, standard answer match_regex flag
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade efb35676026c -> 5c7fdadae813, match_any_keywords flag for standard answers
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5c7fdadae813 -> c99d76fcd298, add nullable to persona id in Chat Session
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c99d76fcd298 -> 35e6853a51d5, server default chosen assistants
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 35e6853a51d5 -> 1b8206b29c5d, add_user_delete_cascades
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 1b8206b29c5d -> 61ff3651add4, Add Permission Syncing
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 61ff3651add4 -> 55546a7967ee, assistant_rework
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 55546a7967ee -> 797089dfb4d2, persona_start_date
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 797089dfb4d2 -> bd2921608c3a, non nullable default persona
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade bd2921608c3a -> f32615f71aeb, add custom headers to tools
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade f32615f71aeb -> 46b7a812670f, fix_user__external_user_group_id_fk
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 46b7a812670f -> ac5eaac849f9, add last_pruned to the connector_credential_pair table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade ac5eaac849f9 -> e4334d5b33ba, add_deployment_name_to_llmprovider
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade e4334d5b33ba -> 5d12a446f5c0, add api_version and deployment_name to search settings
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5d12a446f5c0 -> 6756efa39ada, Migrate chat_session and chat_message tables to use UUID primary keys
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 6756efa39ada -> 1b10e1fda030, add additional data to notifications
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 1b10e1fda030 -> 949b4a92a401, remove rt
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 949b4a92a401 -> 5b29123cd710, nullable search settings for historic index attempts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 5b29123cd710 -> 33cb72ea4d80, single tool call per message
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 33cb72ea4d80 -> b72ed7a5db0e, remove description from starter messages
index-1                   | [2025-01-20 22:49:46.747] INFO    container        stdout	[7.597s][info][gc] GC(8) Pause Young (Normal) (G1 Evacuation Pause) 986M->79M(1536M) 9.170ms
index-1                   | [2025-01-20 22:49:47.888] INFO    container        Container.com.yahoo.container.jdisc.state.StateMonitor	Changing health status code from 'initializing' to 'up'
index-1                   | [2025-01-20 22:49:48.232] INFO    container        Container.com.yahoo.jrt.slobrok.api.Mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 7 service names)
index-1                   | [2025-01-20 22:49:48.266] INFO    container        Container.com.yahoo.jrt.slobrok.api.Mirror	successfully connected to location broker tcp/541f2852aac7:19099 (mirror initialized with 7 service names)
index-1                   | [2025-01-20 22:49:48.284] INFO    container        Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'feedapi-handler': min=128, max=128, queue=500
index-1                   | [2025-01-20 22:49:48.323] INFO    container        stdout	[9.174s][info][gc] GC(9) Pause Young (Concurrent Start) (Metadata GC Threshold) 735M->84M(1536M) 5.208ms
index-1                   | [2025-01-20 22:49:48.329] INFO    container        Container.com.yahoo.jdisc.http.server.jetty.JettyHttpServer	Threadpool size: min=48, max=48
index-1                   | [2025-01-20 22:49:48.335] INFO    container        stdout	[9.174s][info][gc] GC(10) Concurrent Mark Cycle
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade b72ed7a5db0e -> c0fd6e4da83a, add recent assistants
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c0fd6e4da83a -> 2daa494a0851, add-group-sync-time
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 2daa494a0851 -> 26b931506ecb, default chosen assistants to none
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 26b931506ecb -> 9cf5c00f72fe, add creator to cc pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 9cf5c00f72fe -> dfbe9e93d3c7, extended_role_for_non_web
index-1                   | [2025-01-20 22:49:48.337] INFO    container        stdout	[9.188s][info][gc] GC(10) Pause Remark 87M->69M(1536M) 2.760ms
index-1                   | [2025-01-20 22:49:48.353] INFO    container        stdout	[9.192s][info][gc] GC(10) Pause Cleanup 70M->70M(1536M) 0.283ms
index-1                   | [2025-01-20 22:49:48.353] INFO    container        stdout	[9.198s][info][gc] GC(10) Concurrent Mark Cycle 23.724ms
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade dfbe9e93d3c7 -> 47e5bef3a1d7, add persona categories
index-1                   | [2025-01-20 22:49:48.466] INFO    container        Container.com.yahoo.container.handler.threadpool.ContainerThreadpoolImpl	Threadpool 'default-handler-common': min=64, max=64, queue=2560
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^
index-1                   | [2025-01-20 22:49:48.612] INFO    container        Container.com.yahoo.jrt.slobrok.api.Register	[RPC @ tcp/541f2852aac7:19100] registering default/container.0/chain.indexing with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:48.645] INFO    container        Container.com.yahoo.container.jdisc.ConfiguredApplication	Switching to the latest deployed set of configurations and components. Application config generation: 2
index-1                   | [2025-01-20 22:49:48.647] INFO    container        Container.com.yahoo.container.jdisc.ConfiguredApplication	Registered name 'vespa/service/default/container.0' at tcp/541f2852aac7:19101 with: [tcp/541f2852aac7:19099]
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 63
index-1                   | [2025-01-20 22:49:48.648] INFO    container        Container.com.yahoo.jrt.slobrok.api.Register	[RPC @ tcp/541f2852aac7:19101] registering vespa/service/default/container.0 with location broker tcp/541f2852aac7:19099 completed successfully
index-1                   | [2025-01-20 22:49:49.944] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.EventLog	Added node only event: Event: storage.0: Altered min distribution bit count from 58 to 8
index-1                   | [2025-01-20 22:49:52.556] INFO    container-clustercontroller Container.com.yahoo.vespa.clustercontroller.core.SystemStateBroadcaster	Cluster 'danswer_index': Publishing cluster state version 3
background-1              | _gdbm.error: [Errno 11] Resource temporarily unavailable: 'celerybeat-schedule'
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   40: Initial schedule setup complete
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:40  : onyx.background.celery.apps.beat Initial schedule setup complete
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  127: _try_updating_schedule starting
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:127 : onyx.background.celery.apps.beat _try_updating_schedule starting
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  130: Found 1 IDs
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:130 : onyx.background.celery.apps.beat Found 1 IDs
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  145: Found 0 existing items in schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:145 : onyx.background.celery.apps.beat Found 0 existing items in schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  149: Processing new tenant: None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:149 : onyx.background.celery.apps.beat Processing new tenant: None
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   65: Fetching tasks to schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:65  : onyx.background.celery.apps.beat Fetching tasks to schedule
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 64
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 65
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 66
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 47e5bef3a1d7 -> 4ee1287bd26a, add_multiple_slack_bot_support
api_server-1              | INFO  [alembic.runtime.migration] 4ee1287bd26a: create_table: slack_bot
api_server-1              | INFO  [alembic.runtime.migration] 4ee1287bd26a: Checking for existing Slack bot.
api_server-1              | WARNI [alembic.runtime.migration] No existing Slack bot tokens found.
api_server-1              | INFO  [alembic.runtime.migration] 4ee1287bd26a: Migration complete.
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 4ee1287bd26a -> 177de57c21c9, display custom llm models
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 177de57c21c9 -> 6d562f86c78b, remove default bot
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 6d562f86c78b -> 93560ba1b118, add web ui option to slack config
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 93560ba1b118 -> abe7378b8217, add indexing trigger to cc_pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade abe7378b8217 -> a8c2065484e6, add auto scroll to user model
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade a8c2065484e6 -> 9f696734098f, Combine Search and Chat
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 9f696734098f -> f7a894b06d02, non-nullbale slack bot id in channel config
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade f7a894b06d02 -> bf7a81109301, delete_input_prompts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade bf7a81109301 -> 94dc3d0236f8, make document set description optional
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 94dc3d0236f8 -> 54a74a0417fc, danswerbot -> onyxbot
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 54a74a0417fc -> dab04867cd88, Add composite index to document_by_connector_credential_pair
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade dab04867cd88 -> 91a0a4d62b14, Milestone
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 91a0a4d62b14 -> 35e518e0ddf4, properly_cascade
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 35e518e0ddf4 -> c0aab6edb6dd, delete workspace
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c0aab6edb6dd -> 2955778aa44c, add chunk count to document
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 2955778aa44c -> 369644546676, add composite index for index attempt time updated
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 369644546676 -> be2ab2aa50ee, fix_capitalization
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade be2ab2aa50ee -> 97dbb53fa8c8, Add SyncRecord
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 97dbb53fa8c8 -> fec3db967bf7, Add time_updated to UserGroup and DocumentSet
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade fec3db967bf7 -> 0f7ff6d75b57, add index to index_attempt.time_created
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 0f7ff6d75b57 -> c5eae4a75a1b, Add chat_message__standard_answer table
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade c5eae4a75a1b -> aeda5f2df4f6, add pinned assistants
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade aeda5f2df4f6 -> 3c6531f32351, add back input prompts
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 3c6531f32351 -> 6fc7886d665d, make categories labels and many to many
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 6fc7886d665d -> 027381bce97c, add shortcut option for users
api_server-1              | INFO  [alembic.runtime.migration] Running upgrade 027381bce97c -> c7bf5721733e, Add has_been_indexed to DocumentByConnectorCredentialPair
api_server-1              | Starting Onyx Api Server
api_server-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
api_server-1              | /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 67
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 68
nginx-1                   | 2025/01/20 22:49:51 [notice] 36#36: start worker process 69
api_server-1              |   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:27 PM      variable_functionality.py   29: Enterprise Edition enabled
api_server-1              | WARNING:  ASGI app factory detected. Using it, but please consider setting the --factory flag explicitly.
api_server-1              | INFO:     Started server process [42]
api_server-1              | INFO:     Waiting for application startup.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                        main.py  187: System recursion limit set to 1000
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       users.py   75: Using Auth Type: basic
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py   88: Using Embedding model: "nomic-ai/nomic-embed-text-v1"
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py   90: Query embedding prefix: ""
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py   91: Passage embedding prefix: "search_document: "
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py   95: Reranking is enabled.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  108: Verifying query preprocessing (NLTK) data is downloaded
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:29 PM               search_runner.py   49: stopwords is already downloaded.
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:29 PM               search_runner.py   49: punkt is already downloaded.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  254: Verifying default connector/credential exist.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  260: Loading built-in tools
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py   94: Added new tool: SearchTool
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py   94: Added new tool: ImageGenerationTool
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py  104: All built-in tools are loaded/verified.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  263: Loading default Prompts and Personas
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py  147: Added SearchTool to Persona ID: 0
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py  147: Added SearchTool to Persona ID: -2
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM              built_in_tools.py  151: Completed adding SearchTool to relevant Personas.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  197: No search config found in KV store.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  123: Verifying Document Index(s) is/are available.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       setup.py  231: Setting up Vespa (attempt 1/10)...
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:29 PM                       index.py  154: Deploying Vespa application package to http://index:19071/application/v2/tenant/default/prepareandactivate
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:31 PM                       setup.py  239: Vespa setup complete.
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:31 PM                       setup.py  141: Model Server: http://inference_model_server:9000
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:31 PM                       utils.py  130: Initialized HuggingFaceTokenizer for: nomic-ai/nomic-embed-text-v1
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM                       setup.py  300: No existing docs or connectors found. Checking GPU availability for multipass indexing.
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM                       setup.py  304: GPU available: False
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:33 PM                       setup.py  308: Updating multipass indexing setting to: False
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM             search_settings.py  213: Current search settings updated successfully
api_server-1              | [94mNOTICE[0m:   01/20/2025 10:49:33 PM                       setup.py  320: Updated settings with GPU availability: False
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM                   load_docs.py  133: Seeding initial documents
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM           indexing_pipeline.py  263: Upserted 6 changed docs out of 6 total docs into the DB
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:33 PM                   load_docs.py  214: Indexing seeding documents into Vespa (Vespa may take a few seconds to become ready after receiving the schema)
api_server-1              | [93mWARNING[0m:  01/20/2025 10:49:48 PM                         api.py   40: [Errno 111] Connection refused, retrying in 0.1 seconds...
api_server-1              | INFO:     Application startup complete.
api_server-1              | INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:51 PM                    h11_impl.py  499: 172.18.0.10:39856 - "GET /health HTTP/1.1" 200
api_server-1              | [92mINFO[0m:     01/20/2025 10:49:51 PM                    h11_impl.py  499: 172.18.0.1:40218 - "GET /health HTTP/1.1" 200
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  159: Schedule update required
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:159 : onyx.background.celery.apps.beat Schedule update required
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  186: _try_updating_schedule: Schedule updated successfully
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:186 : onyx.background.celery.apps.beat _try_updating_schedule: Schedule updated successfully
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   35: Set reload interval to 0:02:00
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:35  : onyx.background.celery.apps.beat Set reload interval to 0:02:00
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  202: beat_init signal received.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:202 : onyx.background.celery.apps.beat beat_init signal received.
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    app_base.py  210: Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM     app_base.py:210 : onyx.utils.logger Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    app_base.py  237: Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM     app_base.py:237 : onyx.utils.logger Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   49: Reload interval reached, initiating task update
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:49  : onyx.background.celery.apps.beat Reload interval reached, initiating task update
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  127: _try_updating_schedule starting
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:127 : onyx.background.celery.apps.beat _try_updating_schedule starting
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  130: Found 1 IDs
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:130 : onyx.background.celery.apps.beat Found 1 IDs
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  145: Found 0 existing items in schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:145 : onyx.background.celery.apps.beat Found 0 existing items in schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  149: Processing new tenant: None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:149 : onyx.background.celery.apps.beat Processing new tenant: None
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   65: Fetching tasks to schedule
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:65  : onyx.background.celery.apps.beat Fetching tasks to schedule
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py  154: _try_updating_schedule: Current schedule is up to date, no changes needed
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:154 : onyx.background.celery.apps.beat _try_updating_schedule: Current schedule is up to date, no changes needed
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                        beat.py   58: Task update completed, reset reload timer
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:16 PM         beat.py:58  : onyx.background.celery.apps.beat Task update completed, reset reload timer
background-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
background-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
background-1              | The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
background-1              | 0it [00:00, ?it/s]0it [00:00, ?it/s]
background-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
background-1              | /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
background-1              |   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4
background-1              | /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
background-1              |   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4
background-1              | /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
background-1              |   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4
background-1              | /usr/local/lib/python3.11/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.
background-1              |   from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  895: Starting SlackbotHandler
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  120: Initializing SlackbotHandler
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  159: Retrieved pod ID: 682469d796c6
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  132: Pod ID: 682469d796c6
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  137: Signal handlers registered
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  140: Starting Prometheus metrics server
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  142: Prometheus metrics server started
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  145: Starting background threads
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  155: Background threads started
background-1              | [94mNOTICE[0m:   01/20/2025 10:49:16 PM      variable_functionality.py   29: Enterprise Edition enabled
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM                    listener.py  900: Verifying query preprocessing (NLTK) data is downloaded
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM               search_runner.py   49: stopwords is already downloaded.
background-1              | [92mINFO[0m:     01/20/2025 10:49:16 PM               search_runner.py   49: punkt is already downloaded.
background-1              | [91mERROR[0m:    01/20/2025 10:49:16 PM                    listener.py  306: Error fetching Slack bots for tenant None: (psycopg2.errors.UndefinedTable) relation "slack_bot" does not exist
background-1              | LINE 2: FROM slack_bot
background-1              |              ^
background-1              | 
background-1              | [SQL: SELECT slack_bot.id, slack_bot.name, slack_bot.enabled, slack_bot.bot_token, slack_bot.app_token 
background-1              | FROM slack_bot]
background-1              | (Background on this error at: https://sqlalche.me/e/20/f405)
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1968, in _exec_single_context
background-1              |     self.dialect.do_execute(
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 920, in do_execute
background-1              |     cursor.execute(statement, parameters)
background-1              | psycopg2.errors.UndefinedTable: relation "slack_bot" does not exist
background-1              | LINE 2: FROM slack_bot
background-1              |              ^
background-1              | 
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/onyxbot/slack/listener.py", line 301, in acquire_tenants
background-1              |     bots = list(fetch_slack_bots(db_session=db_session))
background-1              |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/db/slack_bot.py", line 76, in fetch_slack_bots
background-1              |     return db_session.scalars(select(SlackBot)).all()
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2344, in scalars
background-1              |     return self._execute_internal(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 2127, in _execute_internal
background-1              |     result: Result[Any] = compile_state_cls.orm_execute_statement(
background-1              |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/context.py", line 293, in orm_execute_statement
background-1              |     result = conn.execute(
background-1              |              ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1413, in execute
background-1              |     return meth(
background-1              |            ^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 483, in _execute_on_connection
background-1              |     return connection._execute_clauseelement(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1637, in _execute_clauseelement
background-1              |     ret = self._execute_context(
background-1              |           ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
background-1              |     return self._exec_single_context(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1987, in _exec_single_context
background-1              |     self._handle_dbapi_exception(
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2344, in _handle_dbapi_exception
background-1              |     raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1968, in _exec_single_context
background-1              |     self.dialect.do_execute(
background-1              |   File "/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 920, in do_execute
background-1              |     cursor.execute(statement, parameters)
background-1              | sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation "slack_bot" does not exist
background-1              | LINE 2: FROM slack_bot
background-1              |              ^
background-1              | 
background-1              | [SQL: SELECT slack_bot.id, slack_bot.name, slack_bot.enabled, slack_bot.bot_token, slack_bot.app_token 
background-1              | FROM slack_bot]
background-1              | (Background on this error at: https://sqlalche.me/e/20/f405)
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  177: Multiprocessing all start methods: ['fork', 'spawn', 'forkserver']
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  194: Multiprocessing selected start method: spawn
background-1              | /usr/local/lib/python3.11/site-packages/celery/platforms.py:833: SecurityWarning: You're running the worker with superuser privileges: this is
background-1              | absolutely not recommended!
background-1              | 
background-1              | Please specify a different user using the --uid option.
background-1              | 
background-1              | User information: uid=0 euid=0 gid=0 egid=0
background-1              | 
background-1              |   warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                       light.py   57: worker_init signal received.
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                       light.py   59: Concurrency: 24
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  210: Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  237: Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  250: Database: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  279: Database: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  292: Vespa: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  324: Vespa: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  329: Running as a secondary celery worker.
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  337: Waiting for primary worker to be ready...
background-1              | [92mINFO[0m:     01/20/2025 10:49:17 PM                    app_base.py  343: Primary worker is not ready yet. elapsed=0.0 timeout=60.0
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  177: Multiprocessing all start methods: ['fork', 'spawn', 'forkserver']
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  194: Multiprocessing selected start method: spawn
background-1              | /usr/local/lib/python3.11/site-packages/celery/platforms.py:833: SecurityWarning: You're running the worker with superuser privileges: this is
background-1              | absolutely not recommended!
background-1              | 
background-1              | Please specify a different user using the --uid option.
background-1              | 
background-1              | User information: uid=0 euid=0 gid=0 egid=0
background-1              | 
background-1              |   warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                     primary.py   82: worker_init signal received.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  210: Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  237: Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  250: Database: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  279: Database: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  292: Vespa: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  324: Vespa: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                     primary.py   91: Running as the primary celery worker.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                     primary.py  106: Redis INFO REPLICATION: role=master connected_slaves=0
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                     primary.py  128: Primary worker lock: Acquire starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                     primary.py  131: Primary worker lock: Acquire succeeded.
background-1              |  
background-1              |  -------------- primary@682469d796c6 v5.5.0b4 (immunity)
background-1              | --- ***** ----- 
background-1              | -- ******* ---- Linux-6.8.0-1021-aws-x86_64-with-glibc2.36 2025-01-20 22:49:18
background-1              | - *** --- * --- 
background-1              | - ** ---------- [config]
background-1              | - ** ---------- .> app:         onyx.background.celery.apps.primary:0x7f98698e0190
background-1              | - ** ---------- .> transport:   redis://cache:6379/15
background-1              | - ** ---------- .> results:     redis://cache:6379/14
background-1              | - *** --- * --- .> concurrency: 4 (thread)
background-1              | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
background-1              | --- ***** ----- 
background-1              |  -------------- [queues]
background-1              |                 .> celery           exchange=celery(direct) key=celery
background-1              |                 
background-1              | 
background-1              | [tasks]
background-1              |   . autogenerate_usage_report_task
background-1              |   . check_for_connector_deletion_task
background-1              |   . check_for_doc_permissions_sync
background-1              |   . check_for_external_group_sync
background-1              |   . check_for_indexing
background-1              |   . check_for_llm_model_update
background-1              |   . check_for_pruning
background-1              |   . check_for_vespa_sync_task
background-1              |   . check_ttl_management_task
background-1              |   . cloud_check_for_indexing
background-1              |   . connector_external_group_sync_generator_task
background-1              |   . connector_indexing_proxy_task
background-1              |   . connector_permission_sync_generator_task
background-1              |   . connector_pruning_generator_task
background-1              |   . document_by_cc_pair_cleanup_task
background-1              |   . ee.onyx.background.celery.apps.primary.perform_ttl_management_task
background-1              |   . kombu_message_cleanup_task
background-1              |   . monitor_vespa_sync
background-1              |   . update_external_document_permissions_task
background-1              |   . vespa_metadata_sync_task
background-1              | 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM      primary.py:228 :  Scheduled periodic task with hub.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM   connection.py:22  : celery.worker.consumer.connection Connected to redis://cache:6379/15
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM       mingle.py:40  : celery.worker.consumer.mingle mingle: searching for neighbors
background-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  177: Multiprocessing all start methods: ['fork', 'spawn', 'forkserver']
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  194: Multiprocessing selected start method: spawn
background-1              | /usr/local/lib/python3.11/site-packages/celery/platforms.py:833: SecurityWarning: You're running the worker with superuser privileges: this is
background-1              | absolutely not recommended!
background-1              | 
background-1              | Please specify a different user using the --uid option.
background-1              | 
background-1              | User information: uid=0 euid=0 gid=0 egid=0
background-1              | 
background-1              |   warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                       heavy.py   58: worker_init signal received.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  210: Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  237: Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  250: Database: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  279: Database: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  292: Vespa: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  324: Vespa: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  329: Running as a secondary celery worker.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  337: Waiting for primary worker to be ready...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  356: Wait for primary worker completed successfully. Continuing...
background-1              |  
background-1              |  -------------- heavy@682469d796c6 v5.5.0b4 (immunity)
background-1              | --- ***** ----- 
background-1              | -- ******* ---- Linux-6.8.0-1021-aws-x86_64-with-glibc2.36 2025-01-20 22:49:18
background-1              | - *** --- * --- 
background-1              | - ** ---------- [config]
background-1              | - ** ---------- .> app:         onyx.background.celery.apps.heavy:0x7f7b3e902610
background-1              | - ** ---------- .> transport:   redis://cache:6379/15
background-1              | - ** ---------- .> results:     redis://cache:6379/14
background-1              | - *** --- * --- .> concurrency: 4 (thread)
background-1              | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
background-1              | --- ***** ----- 
background-1              |  -------------- [queues]
background-1              |                 .> connector_doc_permissions_sync exchange=connector_doc_permissions_sync(direct) key=connector_doc_permissions_sync
background-1              |                 .> connector_external_group_sync exchange=connector_external_group_sync(direct) key=connector_external_group_sync
background-1              |                 .> connector_pruning exchange=connector_pruning(direct) key=connector_pruning
background-1              | 
background-1              | [tasks]
background-1              |   . check_for_doc_permissions_sync
background-1              |   . check_for_external_group_sync
background-1              |   . check_for_pruning
background-1              |   . connector_external_group_sync_generator_task
background-1              |   . connector_permission_sync_generator_task
background-1              |   . connector_pruning_generator_task
background-1              |   . update_external_document_permissions_task
background-1              | 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM   connection.py:22  : celery.worker.consumer.connection Connected to redis://cache:6379/15
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM       mingle.py:40  : celery.worker.consumer.mingle mingle: searching for neighbors
background-1              | None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  177: Multiprocessing all start methods: ['fork', 'spawn', 'forkserver']
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  194: Multiprocessing selected start method: spawn
background-1              | /usr/local/lib/python3.11/site-packages/celery/platforms.py:833: SecurityWarning: You're running the worker with superuser privileges: this is
background-1              | absolutely not recommended!
background-1              | 
background-1              | Please specify a different user using the --uid option.
background-1              | 
background-1              | User information: uid=0 euid=0 gid=0 egid=0
background-1              | 
background-1              |   warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    indexing.py   59: worker_init signal received.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  210: Redis: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  237: Redis: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  250: Database: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  279: Database: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  292: Vespa: Readiness probe starting.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  324: Vespa: Readiness probe succeeded. Continuing...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  329: Running as a secondary celery worker.
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  337: Waiting for primary worker to be ready...
background-1              | [92mINFO[0m:     01/20/2025 10:49:18 PM                    app_base.py  356: Wait for primary worker completed successfully. Continuing...
background-1              |  
background-1              |  -------------- indexing@682469d796c6 v5.5.0b4 (immunity)
background-1              | --- ***** ----- 
background-1              | -- ******* ---- Linux-6.8.0-1021-aws-x86_64-with-glibc2.36 2025-01-20 22:49:18
background-1              | - *** --- * --- 
background-1              | - ** ---------- [config]
background-1              | - ** ---------- .> app:         onyx.background.celery.apps.indexing:0x7f631bbf2dd0
background-1              | - ** ---------- .> transport:   redis://cache:6379/15
background-1              | - ** ---------- .> results:     redis://cache:6379/14
background-1              | - *** --- * --- .> concurrency: 3 (thread)
background-1              | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
background-1              | --- ***** ----- 
background-1              |  -------------- [queues]
background-1              |                 .> connector_indexing exchange=connector_indexing(direct) key=connector_indexing
background-1              |                 
background-1              | 
background-1              | [tasks]
background-1              |   . check_for_indexing
background-1              |   . cloud_check_for_indexing
background-1              |   . connector_indexing_proxy_task
background-1              | 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM   connection.py:22  : celery.worker.consumer.connection Connected to redis://cache:6379/15
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:18 PM       mingle.py:40  : celery.worker.consumer.mingle mingle: searching for neighbors
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       mingle.py:49  : celery.worker.consumer.mingle mingle: all alone
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM        tasks.py:46  : celery.worker.consumer.tasks Global QoS is disabled. Prefetch count in now static.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM     app_base.py:361 :  worker_ready signal received.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       worker.py:176 : celery.apps.worker primary@682469d796c6 ready.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       mingle.py:49  : celery.worker.consumer.mingle mingle: all alone
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM        tasks.py:46  : celery.worker.consumer.tasks Global QoS is disabled. Prefetch count in now static.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM     app_base.py:361 :  worker_ready signal received.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       worker.py:176 : celery.apps.worker heavy@682469d796c6 ready.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       mingle.py:49  : celery.worker.consumer.mingle mingle: all alone
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM        tasks.py:46  : celery.worker.consumer.tasks Global QoS is disabled. Prefetch count in now static.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM     app_base.py:361 :  worker_ready signal received.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:19 PM       worker.py:176 : celery.apps.worker indexing@682469d796c6 ready.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM        tasks.py:870 :  [monitor_vespa_sync(626a8250-ea12-4669-a694-faefabb5e6a6)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM        tasks.py:921 :  [monitor_vespa_sync(626a8250-ea12-4669-a694-faefabb5e6a6)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM        tasks.py:1034:  [monitor_vespa_sync(626a8250-ea12-4669-a694-faefabb5e6a6)] monitor_vespa_sync finished: elapsed=0.01
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM      control.py:375 : celery.worker.control sync with monitoring@682469d796c6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM      control.py:375 : celery.worker.control sync with monitoring@682469d796c6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:21 PM      control.py:375 : celery.worker.control sync with monitoring@682469d796c6
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_beat entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_worker_heavy entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_worker_indexing entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_worker_light entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_worker_monitoring entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | 2025-01-20 22:49:22,984 INFO success: celery_worker_primary entered RUNNING state, process has stayed up for > than 10 seconds (startsecs)
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:23 PM      control.py:375 : celery.worker.control sync with light@682469d796c6
background-1              | [92mINFO[0m:     01/20/2025 10:49:22 PM                    app_base.py  356: Wait for primary worker completed successfully. Continuing...
background-1              |  
background-1              |  -------------- light@682469d796c6 v5.5.0b4 (immunity)
background-1              | --- ***** ----- 
background-1              | -- ******* ---- Linux-6.8.0-1021-aws-x86_64-with-glibc2.36 2025-01-20 22:49:23
background-1              | - *** --- * --- 
background-1              | - ** ---------- [config]
background-1              | - ** ---------- .> app:         onyx.background.celery.apps.light:0x7fdb7c44a7d0
background-1              | - ** ---------- .> transport:   redis://cache:6379/15
background-1              | - ** ---------- .> results:     redis://cache:6379/14
background-1              | - *** --- * --- .> concurrency: 24 (thread)
background-1              | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
background-1              | --- ***** ----- 
background-1              |  -------------- [queues]
background-1              |                 .> connector_deletion exchange=connector_deletion(direct) key=connector_deletion
background-1              |                 .> doc_permissions_upsert exchange=doc_permissions_upsert(direct) key=doc_permissions_upsert
background-1              |                 .> vespa_metadata_sync exchange=vespa_metadata_sync(direct) key=vespa_metadata_sync
background-1              | 
background-1              | [tasks]
background-1              |   . check_for_connector_deletion_task
background-1              |   . check_for_doc_permissions_sync
background-1              |   . check_for_vespa_sync_task
background-1              |   . connector_permission_sync_generator_task
background-1              |   . document_by_cc_pair_cleanup_task
background-1              |   . monitor_vespa_sync
background-1              |   . update_external_document_permissions_task
background-1              |   . vespa_metadata_sync_task
background-1              | 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:23 PM   connection.py:22  : celery.worker.consumer.connection Connected to redis://cache:6379/15
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:23 PM       mingle.py:40  : celery.worker.consumer.mingle mingle: searching for neighbors
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:23 PM      control.py:375 : celery.worker.control sync with light@682469d796c6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:23 PM      control.py:375 : celery.worker.control sync with light@682469d796c6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:24 PM       mingle.py:43  : celery.worker.consumer.mingle mingle: sync with 4 nodes
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:24 PM       mingle.py:47  : celery.worker.consumer.mingle mingle: sync complete
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:24 PM        tasks.py:46  : celery.worker.consumer.tasks Global QoS is disabled. Prefetch count in now static.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:24 PM     app_base.py:361 :  worker_ready signal received.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:24 PM       worker.py:176 : celery.apps.worker light@682469d796c6 ready.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:26 PM        tasks.py:870 :  [monitor_vespa_sync(6a2b7505-8075-4755-b421-a6a361efc16b)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:26 PM        tasks.py:921 :  [monitor_vespa_sync(6a2b7505-8075-4755-b421-a6a361efc16b)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:26 PM        tasks.py:1034:  [monitor_vespa_sync(6a2b7505-8075-4755-b421-a6a361efc16b)] monitor_vespa_sync finished: elapsed=0.01
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:31 PM        tasks.py:870 :  [monitor_vespa_sync(c5e36316-5189-43ed-930f-1f21ab906cfb)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:31 PM        tasks.py:921 :  [monitor_vespa_sync(c5e36316-5189-43ed-930f-1f21ab906cfb)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:31 PM        tasks.py:1034:  [monitor_vespa_sync(c5e36316-5189-43ed-930f-1f21ab906cfb)] monitor_vespa_sync finished: elapsed=0.03
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:31 PM        tasks.py:361 :  [check_for_indexing(f63a7ad0-33e3-4251-b00a-67168a97d948)] check_for_indexing finished: elapsed=0.04
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:870 :  [monitor_vespa_sync(dc6bd6fc-904a-4846-a6be-3052da0cea9c)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:215 :  [check_for_vespa_sync_task(078324d3-27d2-4f9b-af91-9624332c5c3f)] Stale documents found (at least 6). Generating sync tasks by cc pair.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:219 :  [check_for_vespa_sync_task(078324d3-27d2-4f9b-af91-9624332c5c3f)] RedisConnector.generate_tasks starting by cc_pair. Documents spanning multiple cc_pairs will only be synced once.
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:246 :  [check_for_vespa_sync_task(078324d3-27d2-4f9b-af91-9624332c5c3f)] RedisConnector.generate_tasks finished for single cc_pair. cc_pair=2 tasks_generated=6 tasks_possible=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:262 :  [check_for_vespa_sync_task(078324d3-27d2-4f9b-af91-9624332c5c3f)] RedisConnector.generate_tasks finished for all cc_pairs. total_tasks_generated=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:921 :  [monitor_vespa_sync(dc6bd6fc-904a-4846-a6be-3052da0cea9c)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:428 :  [monitor_vespa_sync(dc6bd6fc-904a-4846-a6be-3052da0cea9c)] Stale document sync progress: remaining=6 initial=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:36 PM        tasks.py:1034:  [monitor_vespa_sync(dc6bd6fc-904a-4846-a6be-3052da0cea9c)] monitor_vespa_sync finished: elapsed=0.03
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:36 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 1 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [93mWARNING[0m:  WARNING  01/20/2025 10:49:37 PM          api.py:40  : retry.api [Errno 111] Connection refused, retrying in 2 seconds...
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_854e8740-bce9-4eea-8b69-977dbe27f202)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/enterprise_search
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_20808d96-c845-4e83-b782-54ba8bab1f7e)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/overview
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_0d9fafbf-7f24-4324-9b68-3a5dcb2c0d18)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/operations
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_5415ff3f-ae84-46de-bb2b-b4ba2a2d959d)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/sales
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_b724f7e3-77d1-4379-984d-e42ed561ba5e)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/customer_support
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [91mERROR[0m:    ERROR    01/20/2025 10:49:39 PM        tasks.py:1123:  [vespa_metadata_sync_task(connectorsync_2_ba541509-13b2-4452-92bd-d13b0fa5397e)] Unexpected exception during vespa metadata sync: doc=https://docs.onyx.app/more/use_cases/ai_platform
background-1              | Traceback (most recent call last):
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
background-1              |     yield
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 233, in handle_request
background-1              |     resp = self._pool.handle_request(req)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
background-1              |     raise exc from None
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
background-1              |     response = connection.handle_request(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
background-1              |     raise exc
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
background-1              |     stream = self._connect(request)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 122, in _connect
background-1              |     stream = self._network_backend.connect_tcp(**kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
background-1              |     with map_exceptions(exc_map):
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
background-1              |     raise to_exc(exc) from exc
background-1              | httpcore.ConnectError: [Errno 111] Connection refused
background-1              | 
background-1              | The above exception was the direct cause of the following exception:
background-1              | 
background-1              | Traceback (most recent call last):
background-1              |   File "/app/onyx/background/celery/tasks/vespa/tasks.py", line 1078, in vespa_metadata_sync_task
background-1              |     chunks_affected = retry_index.update_single(
background-1              |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 336, in wrapped_f
background-1              |     return copy(f, *args, **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 475, in __call__
background-1              |     do = self.iter(retry_state=retry_state)
background-1              |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 376, in iter
background-1              |     result = action(retry_state)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 398, in <lambda>
background-1              |     self._add_action_func(lambda rs: rs.outcome.result())
background-1              |                                      ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
background-1              |     return self.__get_result()
background-1              |            ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
background-1              |     raise self._exception
background-1              |   File "/usr/local/lib/python3.11/site-packages/tenacity/__init__.py", line 478, in __call__
background-1              |     result = fn(*args, **kwargs)
background-1              |              ^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/background/celery/tasks/shared/RetryDocumentIndex.py", line 57, in update_single
background-1              |     return self.index.update_single(
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 597, in update_single
background-1              |     enriched_doc_infos = VespaIndex.enrich_basic_chunk_info(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/index.py", line 796, in enrich_basic_chunk_info
background-1              |     last_indexed_chunk = check_for_final_chunk_existence(
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 273, in check_for_final_chunk_existence
background-1              |     if not _does_doc_chunk_exist(doc_chunk_id, index_name, http_client):
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/decorator.py", line 232, in fun
background-1              |     return caller(func, *(extras + args), **kw)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 73, in retry_decorator
background-1              |     return __retry_internal(partial(f, *args, **kwargs), exceptions, tries, delay, max_delay, backoff, jitter,
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/retry/api.py", line 33, in __retry_internal
background-1              |     return f()
background-1              |            ^^^
background-1              |   File "/app/onyx/document_index/vespa/indexing_utils.py", line 65, in _does_doc_chunk_exist
background-1              |     doc_fetch_response = http_client.get(doc_url)
background-1              |                          ^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1054, in get
background-1              |     return self.request(
background-1              |            ^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 827, in request
background-1              |     return self.send(request, auth=auth, follow_redirects=follow_redirects)
background-1              |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
background-1              |     response = self._send_handling_auth(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
background-1              |     response = self._send_handling_redirects(
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
background-1              |     response = self._send_single_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_client.py", line 1015, in _send_single_request
background-1              |     response = transport.handle_request(request)
background-1              |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 232, in handle_request
background-1              |     with map_httpcore_exceptions():
background-1              |   File "/usr/local/lib/python3.11/contextlib.py", line 158, in __exit__
background-1              |     self.gen.throw(typ, value, traceback)
background-1              |   File "/usr/local/lib/python3.11/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
background-1              |     raise mapped_exc(message) from exc
background-1              | httpx.ConnectError: [Errno 111] Connection refused
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:41 PM        tasks.py:870 :  [monitor_vespa_sync(ef083984-616d-4c77-a93e-61a417eaf45c)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:41 PM        tasks.py:921 :  [monitor_vespa_sync(ef083984-616d-4c77-a93e-61a417eaf45c)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:41 PM        tasks.py:428 :  [monitor_vespa_sync(ef083984-616d-4c77-a93e-61a417eaf45c)] Stale document sync progress: remaining=6 initial=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:41 PM        tasks.py:1034:  [monitor_vespa_sync(ef083984-616d-4c77-a93e-61a417eaf45c)] monitor_vespa_sync finished: elapsed=0.01
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:46 PM        tasks.py:870 :  [monitor_vespa_sync(0a34d006-c4e2-4bfd-9b52-046bfeb4ceb4)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:46 PM        tasks.py:921 :  [monitor_vespa_sync(0a34d006-c4e2-4bfd-9b52-046bfeb4ceb4)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:46 PM        tasks.py:428 :  [monitor_vespa_sync(0a34d006-c4e2-4bfd-9b52-046bfeb4ceb4)] Stale document sync progress: remaining=6 initial=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:46 PM        tasks.py:361 :  [check_for_indexing(0ab51715-d9d9-4771-9e6c-5ad3b37c80aa)] check_for_indexing finished: elapsed=0.03
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:46 PM        tasks.py:1034:  [monitor_vespa_sync(0a34d006-c4e2-4bfd-9b52-046bfeb4ceb4)] monitor_vespa_sync finished: elapsed=0.03
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:51 PM        tasks.py:870 :  [monitor_vespa_sync(141bb6e2-618e-4951-b128-844a70252a65)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:51 PM        tasks.py:921 :  [monitor_vespa_sync(141bb6e2-618e-4951-b128-844a70252a65)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:51 PM        tasks.py:428 :  [monitor_vespa_sync(141bb6e2-618e-4951-b128-844a70252a65)] Stale document sync progress: remaining=6 initial=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:51 PM        tasks.py:1034:  [monitor_vespa_sync(141bb6e2-618e-4951-b128-844a70252a65)] monitor_vespa_sync finished: elapsed=0.01
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:56 PM        tasks.py:870 :  [monitor_vespa_sync(2b8595d7-4425-4e7a-9c75-88a4577a7d59)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:56 PM        tasks.py:921 :  [monitor_vespa_sync(2b8595d7-4425-4e7a-9c75-88a4577a7d59)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:56 PM        tasks.py:428 :  [monitor_vespa_sync(2b8595d7-4425-4e7a-9c75-88a4577a7d59)] Stale document sync progress: remaining=0 initial=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:56 PM        tasks.py:434 :  [monitor_vespa_sync(2b8595d7-4425-4e7a-9c75-88a4577a7d59)] Successfully synced stale documents. count=6
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:56 PM        tasks.py:1034:  [monitor_vespa_sync(2b8595d7-4425-4e7a-9c75-88a4577a7d59)] monitor_vespa_sync finished: elapsed=0.02
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_854e8740-bce9-4eea-8b69-977dbe27f202)] doc=https://docs.onyx.app/more/use_cases/enterprise_search action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_5415ff3f-ae84-46de-bb2b-b4ba2a2d959d)] doc=https://docs.onyx.app/more/use_cases/sales action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_20808d96-c845-4e83-b782-54ba8bab1f7e)] doc=https://docs.onyx.app/more/use_cases/overview action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_0d9fafbf-7f24-4324-9b68-3a5dcb2c0d18)] doc=https://docs.onyx.app/more/use_cases/operations action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_ba541509-13b2-4452-92bd-d13b0fa5397e)] doc=https://docs.onyx.app/more/use_cases/ai_platform action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:49:55 PM        tasks.py:1098:  [vespa_metadata_sync_task(connectorsync_2_b724f7e3-77d1-4379-984d-e42ed561ba5e)] doc=https://docs.onyx.app/more/use_cases/customer_support action=sync chunks=0
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:50:01 PM        tasks.py:870 :  [monitor_vespa_sync(46b87dc8-dc69-4e2e-91a0-d2d6aef18774)] monitor_vespa_sync starting: tenant=None
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:50:01 PM        tasks.py:921 :  [monitor_vespa_sync(46b87dc8-dc69-4e2e-91a0-d2d6aef18774)] Queue lengths: celery=0 indexing=0 indexing_prefetched=0 sync=0 deletion=0 pruning=0 permissions_sync=0 external_group_sync=0 permissions_upsert=0 
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:50:01 PM        tasks.py:361 :  [check_for_indexing(d8faaf22-68ad-4b50-ad88-55344a3ac579)] check_for_indexing finished: elapsed=0.03
background-1              | [92mINFO[0m:     INFO     01/20/2025 10:50:01 PM        tasks.py:1034:  [monitor_vespa_sync(46b87dc8-dc69-4e2e-91a0-d2d6aef18774)] monitor_vespa_sync finished: elapsed=0.03
